[2024-05-15 09:15:20,253] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-15 09:15:22,992] [INFO] [runner.py:452:main] Using IP address of 10.0.16.14 for node 10.0.16.14
[2024-05-15 09:15:22,993] [INFO] [multinode_runner.py:70:get_cmd] Running on the following workers: 10.0.16.14,10.0.16.13
[2024-05-15 09:15:22,994] [INFO] [runner.py:555:main] cmd = pdsh -S -f 1024 -w 10.0.16.14,10.0.16.13 export PYTHONPATH=/home/kechengsheji/DeepSpeedExamples/inference/huggingface/zero-shot-classification;  cd /home/kechengsheji/DeepSpeedExamples/inference/huggingface/zero-shot-classification; /home/kechengsheji/anaconda3/envs/Test04/bin/python -u -m deepspeed.launcher.launch --world_info=eyIxMC4wLjE2LjE0IjogWzAsIDFdLCAiMTAuMC4xNi4xMyI6IFswLCAxXX0= --node_rank=%n --master_addr=10.0.16.14 --master_port=29500 test-deberta.py --batch_size '128'
10.0.16.13: [2024-05-15 17:15:24,475] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
10.0.16.13: [2024-05-15 17:15:24,823] [INFO] [launch.py:145:main] WORLD INFO DICT: {'10.0.16.14': [0, 1], '10.0.16.13': [0, 1]}
10.0.16.13: [2024-05-15 17:15:24,823] [INFO] [launch.py:151:main] nnodes=2, num_local_procs=2, node_rank=1
10.0.16.13: [2024-05-15 17:15:24,823] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'10.0.16.14': [0, 1], '10.0.16.13': [2, 3]})
10.0.16.13: [2024-05-15 17:15:24,823] [INFO] [launch.py:163:main] dist_world_size=4
10.0.16.13: [2024-05-15 17:15:24,823] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1
10.0.16.14: [2024-05-15 09:15:25,046] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
10.0.16.14: [2024-05-15 09:15:25,397] [INFO] [launch.py:145:main] WORLD INFO DICT: {'10.0.16.14': [0, 1], '10.0.16.13': [0, 1]}
10.0.16.14: [2024-05-15 09:15:25,397] [INFO] [launch.py:151:main] nnodes=2, num_local_procs=2, node_rank=0
10.0.16.14: [2024-05-15 09:15:25,397] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'10.0.16.14': [0, 1], '10.0.16.13': [2, 3]})
10.0.16.14: [2024-05-15 09:15:25,397] [INFO] [launch.py:163:main] dist_world_size=4
10.0.16.14: [2024-05-15 09:15:25,397] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1
10.0.16.13: [2024-05-15 17:15:26,531] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
10.0.16.13: [2024-05-15 17:15:26,608] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
10.0.16.14: [2024-05-15 09:15:27,206] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
10.0.16.14: [2024-05-15 09:15:27,214] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
10.0.16.14: [2024-05-15 09:15:32,573] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.5+fc9e1ee0, git-hash=fc9e1ee0, git-branch=HEAD
10.0.16.14: config_dict: {'mp_size': 4, 'dtype': torch.float32, 'tp_proportion': (7, 1)}
10.0.16.14: [2024-05-15 09:15:32,574] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter mp_size is deprecated use tensor_parallel.tp_size instead
10.0.16.14: ds_inference_config: replace_with_kernel_inject=False dtype=torch.float32 tensor_parallel=DeepSpeedTPConfig(enabled=True, tp_size=4, mpu=None, tp_group=None) enable_cuda_graph=False zero=DeepSpeedZeroConfig(stage=0, contiguous_gradients=True, reduce_scatter=True, reduce_bucket_size=500,000,000, allgather_partitions=True, allgather_bucket_size=500,000,000, overlap_comm=False, load_from_fp32_weights=True, elastic_checkpoint=False, offload_param=None, offload_optimizer=None, sub_group_size=1,000,000,000, cpu_offload_param=None, cpu_offload_use_pin_memory=None, cpu_offload=None, prefetch_bucket_size=50,000,000, param_persistence_threshold=100,000, model_persistence_threshold=sys.maxsize, max_live_parameters=1,000,000,000, max_reuse_distance=1,000,000,000, gather_16bit_weights_on_model_save=False, stage3_gather_fp16_weights_on_model_save=False, ignore_unused_parameters=True, legacy_stage1=False, round_robin_gradients=False, mics_shard_size=-1, mics_hierarchical_params_gather=False, memory_efficient_linear=True) triangular_masking=True moe=DeepSpeedMoEConfig(enabled=True, ep_size=1, moe_experts=[1], type='standard', ep_mp_group=None, ep_group=None) quant=QuantizationConfig(enabled=True, activation=ActivationQuantConfig(q_type='symmetric', q_groups=1, enabled=True, num_bits=8), weight=WeightQuantConfig(q_type='symmetric', q_groups=1, enabled=True, num_bits=8), qkv=QKVQuantConfig(enabled=True)) checkpoint=None base_dir=None set_empty_params=False save_mp_checkpoint_path=None checkpoint_config=InferenceCheckpointConfig(checkpoint_dir=None, save_mp_checkpoint_path=None, base_dir=None) return_tuple=True training_mp_size=1 replace_method='auto' injection_policy=None injection_policy_tuple=None config=None max_out_tokens=1024 min_out_tokens=1 transposed_mode=False mpu=None ep_size=1 ep_group=None ep_mp_group=None moe_experts=[1] moe_type='standard' tp_proportion=(7, 1)
10.0.16.14: [2024-05-15 09:15:32,575] [INFO] [logging.py:96:log_dist] [Rank -1] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
10.0.16.14: [2024-05-15 09:15:32,577] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
10.0.16.14: [2024-05-15 09:15:32,577] [INFO] [comm.py:594:init_distributed] cdb=None
10.0.16.14: [2024-05-15 09:15:32,748] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.5+fc9e1ee0, git-hash=fc9e1ee0, git-branch=HEAD
10.0.16.14: config_dict: {'mp_size': 4, 'dtype': torch.float32, 'tp_proportion': (7, 1)}
10.0.16.14: [2024-05-15 09:15:32,749] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter mp_size is deprecated use tensor_parallel.tp_size instead
10.0.16.14: ds_inference_config: replace_with_kernel_inject=False dtype=torch.float32 tensor_parallel=DeepSpeedTPConfig(enabled=True, tp_size=4, mpu=None, tp_group=None) enable_cuda_graph=False zero=DeepSpeedZeroConfig(stage=0, contiguous_gradients=True, reduce_scatter=True, reduce_bucket_size=500,000,000, allgather_partitions=True, allgather_bucket_size=500,000,000, overlap_comm=False, load_from_fp32_weights=True, elastic_checkpoint=False, offload_param=None, offload_optimizer=None, sub_group_size=1,000,000,000, cpu_offload_param=None, cpu_offload_use_pin_memory=None, cpu_offload=None, prefetch_bucket_size=50,000,000, param_persistence_threshold=100,000, model_persistence_threshold=sys.maxsize, max_live_parameters=1,000,000,000, max_reuse_distance=1,000,000,000, gather_16bit_weights_on_model_save=False, stage3_gather_fp16_weights_on_model_save=False, ignore_unused_parameters=True, legacy_stage1=False, round_robin_gradients=False, mics_shard_size=-1, mics_hierarchical_params_gather=False, memory_efficient_linear=True) triangular_masking=True moe=DeepSpeedMoEConfig(enabled=True, ep_size=1, moe_experts=[1], type='standard', ep_mp_group=None, ep_group=None) quant=QuantizationConfig(enabled=True, activation=ActivationQuantConfig(q_type='symmetric', q_groups=1, enabled=True, num_bits=8), weight=WeightQuantConfig(q_type='symmetric', q_groups=1, enabled=True, num_bits=8), qkv=QKVQuantConfig(enabled=True)) checkpoint=None base_dir=None set_empty_params=False save_mp_checkpoint_path=None checkpoint_config=InferenceCheckpointConfig(checkpoint_dir=None, save_mp_checkpoint_path=None, base_dir=None) return_tuple=True training_mp_size=1 replace_method='auto' injection_policy=None injection_policy_tuple=None config=None max_out_tokens=1024 min_out_tokens=1 transposed_mode=False mpu=None ep_size=1 ep_group=None ep_mp_group=None moe_experts=[1] moe_type='standard' tp_proportion=(7, 1)
10.0.16.14: [2024-05-15 09:15:32,749] [INFO] [logging.py:96:log_dist] [Rank -1] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
10.0.16.14: [2024-05-15 09:15:32,752] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
10.0.16.14: [2024-05-15 09:15:32,752] [INFO] [comm.py:594:init_distributed] cdb=None
10.0.16.14: [2024-05-15 09:15:32,752] [INFO] [comm.py:625:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
10.0.16.13: [2024-05-15 17:15:33,058] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.5+fc9e1ee0, git-hash=fc9e1ee0, git-branch=HEAD
10.0.16.13: config_dict: {'mp_size': 4, 'dtype': torch.float32, 'tp_proportion': (7, 1)}
10.0.16.13: [2024-05-15 17:15:33,059] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter mp_size is deprecated use tensor_parallel.tp_size instead
10.0.16.13: ds_inference_config: replace_with_kernel_inject=False dtype=torch.float32 tensor_parallel=DeepSpeedTPConfig(enabled=True, tp_size=4, mpu=None, tp_group=None) enable_cuda_graph=False zero=DeepSpeedZeroConfig(stage=0, contiguous_gradients=True, reduce_scatter=True, reduce_bucket_size=500,000,000, allgather_partitions=True, allgather_bucket_size=500,000,000, overlap_comm=False, load_from_fp32_weights=True, elastic_checkpoint=False, offload_param=None, offload_optimizer=None, sub_group_size=1,000,000,000, cpu_offload_param=None, cpu_offload_use_pin_memory=None, cpu_offload=None, prefetch_bucket_size=50,000,000, param_persistence_threshold=100,000, model_persistence_threshold=sys.maxsize, max_live_parameters=1,000,000,000, max_reuse_distance=1,000,000,000, gather_16bit_weights_on_model_save=False, stage3_gather_fp16_weights_on_model_save=False, ignore_unused_parameters=True, legacy_stage1=False, round_robin_gradients=False, mics_shard_size=-1, mics_hierarchical_params_gather=False, memory_efficient_linear=True) triangular_masking=True moe=DeepSpeedMoEConfig(enabled=True, ep_size=1, moe_experts=[1], type='standard', ep_mp_group=None, ep_group=None) quant=QuantizationConfig(enabled=True, activation=ActivationQuantConfig(q_type='symmetric', q_groups=1, enabled=True, num_bits=8), weight=WeightQuantConfig(q_type='symmetric', q_groups=1, enabled=True, num_bits=8), qkv=QKVQuantConfig(enabled=True)) checkpoint=None base_dir=None set_empty_params=False save_mp_checkpoint_path=None checkpoint_config=InferenceCheckpointConfig(checkpoint_dir=None, save_mp_checkpoint_path=None, base_dir=None) return_tuple=True training_mp_size=1 replace_method='auto' injection_policy=None injection_policy_tuple=None config=None max_out_tokens=1024 min_out_tokens=1 transposed_mode=False mpu=None ep_size=1 ep_group=None ep_mp_group=None moe_experts=[1] moe_type='standard' tp_proportion=(7, 1)
10.0.16.13: [2024-05-15 17:15:33,060] [INFO] [logging.py:96:log_dist] [Rank -1] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
10.0.16.13: [2024-05-15 17:15:33,062] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
10.0.16.13: [2024-05-15 17:15:33,062] [INFO] [comm.py:594:init_distributed] cdb=None
10.0.16.13: [2024-05-15 17:15:33,103] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.5+fc9e1ee0, git-hash=fc9e1ee0, git-branch=HEAD
10.0.16.13: config_dict: {'mp_size': 4, 'dtype': torch.float32, 'tp_proportion': (7, 1)}
10.0.16.13: [2024-05-15 17:15:33,104] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter mp_size is deprecated use tensor_parallel.tp_size instead
10.0.16.13: ds_inference_config: replace_with_kernel_inject=False dtype=torch.float32 tensor_parallel=DeepSpeedTPConfig(enabled=True, tp_size=4, mpu=None, tp_group=None) enable_cuda_graph=False zero=DeepSpeedZeroConfig(stage=0, contiguous_gradients=True, reduce_scatter=True, reduce_bucket_size=500,000,000, allgather_partitions=True, allgather_bucket_size=500,000,000, overlap_comm=False, load_from_fp32_weights=True, elastic_checkpoint=False, offload_param=None, offload_optimizer=None, sub_group_size=1,000,000,000, cpu_offload_param=None, cpu_offload_use_pin_memory=None, cpu_offload=None, prefetch_bucket_size=50,000,000, param_persistence_threshold=100,000, model_persistence_threshold=sys.maxsize, max_live_parameters=1,000,000,000, max_reuse_distance=1,000,000,000, gather_16bit_weights_on_model_save=False, stage3_gather_fp16_weights_on_model_save=False, ignore_unused_parameters=True, legacy_stage1=False, round_robin_gradients=False, mics_shard_size=-1, mics_hierarchical_params_gather=False, memory_efficient_linear=True) triangular_masking=True moe=DeepSpeedMoEConfig(enabled=True, ep_size=1, moe_experts=[1], type='standard', ep_mp_group=None, ep_group=None) quant=QuantizationConfig(enabled=True, activation=ActivationQuantConfig(q_type='symmetric', q_groups=1, enabled=True, num_bits=8), weight=WeightQuantConfig(q_type='symmetric', q_groups=1, enabled=True, num_bits=8), qkv=QKVQuantConfig(enabled=True)) checkpoint=None base_dir=None set_empty_params=False save_mp_checkpoint_path=None checkpoint_config=InferenceCheckpointConfig(checkpoint_dir=None, save_mp_checkpoint_path=None, base_dir=None) return_tuple=True training_mp_size=1 replace_method='auto' injection_policy=None injection_policy_tuple=None config=None max_out_tokens=1024 min_out_tokens=1 transposed_mode=False mpu=None ep_size=1 ep_group=None ep_mp_group=None moe_experts=[1] moe_type='standard' tp_proportion=(7, 1)
10.0.16.13: [2024-05-15 17:15:33,104] [INFO] [logging.py:96:log_dist] [Rank -1] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
10.0.16.13: [2024-05-15 17:15:33,107] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
10.0.16.13: [2024-05-15 17:15:33,107] [INFO] [comm.py:594:init_distributed] cdb=None
10.0.16.14: tensor_parallel_group: <torch.distributed.distributed_c10d.ProcessGroup object at 0x7f8628ad5b30>
10.0.16.13: tensor_parallel_group: <torch.distributed.distributed_c10d.ProcessGroup object at 0x7f26f88ce970>
10.0.16.13: !deepspeed engine has no moe layers
10.0.16.14: tensor_parallel_group: <torch.distributed.distributed_c10d.ProcessGroup object at 0x7f0d7e002570>
10.0.16.13: tensor_parallel_group: <torch.distributed.distributed_c10d.ProcessGroup object at 0x7f263c026a70>
10.0.16.13: !deepspeed engine has no moe layers
10.0.16.14: _replace_module: DebertaV2ForSequenceClassification(
10.0.16.14:   (deberta): DebertaV2Model(
10.0.16.14:     (embeddings): DebertaV2Embeddings(
10.0.16.14:       (word_embeddings): Embedding(128100, 1024, padding_idx=0)
10.0.16.14:       (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
10.0.16.14:       (dropout): StableDropout()
10.0.16.14:     )
10.0.16.14:     (encoder): DebertaV2Encoder(
10.0.16.14:       (layer): ModuleList(
10.0.16.14:         (0-23): 24 x DebertaV2Layer(
10.0.16.14:           (attention): DebertaV2Attention(
10.0.16.14:             (self): DisentangledSelfAttention(
10.0.16.14:               (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
10.0.16.14:               (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
10.0.16.14:               (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
10.0.16.14:               (pos_dropout): StableDropout()
10.0.16.14:               (dropout): StableDropout()
10.0.16.14:             )
10.0.16.14:             (output): DebertaV2SelfOutput(
10.0.16.14:               (dense): Linear(in_features=1024, out_features=1024, bias=True)
10.0.16.14:               (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
10.0.16.14:               (dropout): StableDropout()
10.0.16.14:             )
10.0.16.14:           )
10.0.16.14:           (intermediate): DebertaV2Intermediate(
10.0.16.14:             (dense): Linear(in_features=1024, out_features=4096, bias=True)
10.0.16.14:             (intermediate_act_fn): GELUActivation()
10.0.16.14:           )
10.0.16.14:           (output): DebertaV2Output(
10.0.16.14:             (dense): Linear(in_features=4096, out_features=1024, bias=True)
10.0.16.14:             (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
10.0.16.14:             (dropout): StableDropout()
10.0.16.14:           )
10.0.16.14:         )
10.0.16.14:       )
10.0.16.14:       (rel_embeddings): Embedding(512, 1024)
10.0.16.14:       (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
10.0.16.14:     )
10.0.16.14:   )
10.0.16.14:   (pooler): ContextPooler(
10.0.16.14:     (dense): Linear(in_features=1024, out_features=1024, bias=True)
10.0.16.14:     (dropout): StableDropout()
10.0.16.14:   )
10.0.16.14:   (classifier): Linear(in_features=1024, out_features=2, bias=True)
10.0.16.14:   (dropout): StableDropout()
10.0.16.14: )
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.14: _replace_module: DebertaV2Model(
10.0.16.14:   (embeddings): DebertaV2Embeddings(
10.0.16.14:     (word_embeddings): Embedding(128100, 1024, padding_idx=0)
10.0.16.14:     (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
10.0.16.14:     (dropout): StableDropout()
10.0.16.14:   )
10.0.16.14:   (encoder): DebertaV2Encoder(
10.0.16.14:     (layer): ModuleList(
10.0.16.14:       (0-23): 24 x DebertaV2Layer(
10.0.16.14:         (attention): DebertaV2Attention(
10.0.16.14:           (self): DisentangledSelfAttention(
10.0.16.14:             (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
10.0.16.14:             (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
10.0.16.14:             (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
10.0.16.14:             (pos_dropout): StableDropout()
10.0.16.14:             (dropout): StableDropout()
10.0.16.14:           )
10.0.16.14:           (output): DebertaV2SelfOutput(
10.0.16.14:             (dense): Linear(in_features=1024, out_features=1024, bias=True)
10.0.16.14:             (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
10.0.16.14:             (dropout): StableDropout()
10.0.16.14:           )
10.0.16.14:         )
10.0.16.14:         (intermediate): DebertaV2Intermediate(
10.0.16.14:           (dense): Linear(in_features=1024, out_features=4096, bias=True)
10.0.16.14:           (intermediate_act_fn): GELUActivation()
10.0.16.14:         )
10.0.16.14:         (output): DebertaV2Output(
10.0.16.14:           (dense): Linear(in_features=4096, out_features=1024, bias=True)
10.0.16.14:           (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
10.0.16.14:           (dropout): StableDropout()
10.0.16.14:         )
10.0.16.14:       )
10.0.16.14:     )
10.0.16.14:     (rel_embeddings): Embedding(512, 1024)
10.0.16.14:     (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
10.0.16.14:   )
10.0.16.14: )
10.0.16.14: _replace_module: DebertaV2Embeddings(
10.0.16.14:   (word_embeddings): Embedding(128100, 1024, padding_idx=0)
10.0.16.14:   (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
10.0.16.14:   (dropout): StableDropout()
10.0.16.14: )
10.0.16.14: _replace_module: Embedding(128100, 1024, padding_idx=0)
10.0.16.14: _replace_module: LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
10.0.16.14: _replace_module: StableDropout()
10.0.16.14: _replace_module: DebertaV2Encoder(
10.0.16.14:   (layer): ModuleList(
10.0.16.14:     (0-23): 24 x DebertaV2Layer(
10.0.16.14:       (attention): DebertaV2Attention(
10.0.16.14:         (self): DisentangledSelfAttention(
10.0.16.14:           (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
10.0.16.14:           (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
10.0.16.14:           (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
10.0.16.14:           (pos_dropout): StableDropout()
10.0.16.14:           (dropout): StableDropout()
10.0.16.14:         )
10.0.16.14:         (output): DebertaV2SelfOutput(
10.0.16.14:           (dense): Linear(in_features=1024, out_features=1024, bias=True)
10.0.16.14:           (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
10.0.16.14:           (dropout): StableDropout()
10.0.16.14:         )
10.0.16.14:       )
10.0.16.14:       (intermediate): DebertaV2Intermediate(
10.0.16.14:         (dense): Linear(in_features=1024, out_features=4096, bias=True)
10.0.16.14:         (intermediate_act_fn): GELUActivation()
10.0.16.14:       )
10.0.16.14:       (output): DebertaV2Output(
10.0.16.14:         (dense): Linear(in_features=4096, out_features=1024, bias=True)
10.0.16.14:         (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
10.0.16.14:         (dropout): StableDropout()
10.0.16.14:       )
10.0.16.14:     )
10.0.16.14:   )
10.0.16.14:   (rel_embeddings): Embedding(512, 1024)
10.0.16.14:   (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
10.0.16.14: )
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: _replace_module: ModuleList(
10.0.16.14:   (0-23): 24 x DebertaV2Layer(
10.0.16.14:     (attention): DebertaV2Attention(
10.0.16.14:       (self): DisentangledSelfAttention(
10.0.16.14:         (query_proj): Linear(in_features=1024, out_features=1024, bias=True)
10.0.16.14:         (key_proj): Linear(in_features=1024, out_features=1024, bias=True)
10.0.16.14:         (value_proj): Linear(in_features=1024, out_features=1024, bias=True)
10.0.16.14:         (pos_dropout): StableDropout()
10.0.16.14:         (dropout): StableDropout()
10.0.16.14:       )
10.0.16.14:       (output): DebertaV2SelfOutput(
10.0.16.14:         (dense): Linear(in_features=1024, out_features=1024, bias=True)
10.0.16.14:         (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
10.0.16.14:         (dropout): StableDropout()
10.0.16.14:       )
10.0.16.14:     )
10.0.16.14:     (intermediate): DebertaV2Intermediate(
10.0.16.14:       (dense): Linear(in_features=1024, out_features=4096, bias=True)
10.0.16.14:       (intermediate_act_fn): GELUActivation()
10.0.16.14:     )
10.0.16.14:     (output): DebertaV2Output(
10.0.16.14:       (dense): Linear(in_features=4096, out_features=1024, bias=True)
10.0.16.14:       (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
10.0.16.14:       (dropout): StableDropout()
10.0.16.14:     )
10.0.16.14:   )
10.0.16.14: )
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: num_attention_heads: 16
10.0.16.14: all_head_size: 1024
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 1024])
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 4096])
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: num_attention_heads: 16
10.0.16.14: all_head_size: 1024
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 1024])
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 4096])
10.0.16.14: replace without policy
10.0.16.14: replace without policyall_reduce_linears: ('output.dense',)
10.0.16.14: 
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: num_attention_heads: 16
10.0.16.14: all_head_size: 1024
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 1024])
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 4096])
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: num_attention_heads: 16
10.0.16.14: all_head_size: 1024
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 1024])
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 4096])
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: num_attention_heads: 16
10.0.16.14: all_head_size: 1024
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 1024])
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 4096])
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: num_attention_heads: 16
10.0.16.14: all_head_size: 1024
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 1024])
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 4096])
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: num_attention_heads: 16
10.0.16.14: all_head_size: 1024
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 1024])
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 4096])
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: num_attention_heads: 16
10.0.16.14: all_head_size: 1024
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 1024])
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 4096])
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: num_attention_heads: 16
10.0.16.14: all_head_size: 1024
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 1024])
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 4096])
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: num_attention_heads: 16
10.0.16.14: all_head_size: 1024
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 1024])
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 4096])
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: num_attention_heads: 16
10.0.16.14: all_head_size: 1024
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 1024])replace without policy
10.0.16.14: 
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 4096])
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: num_attention_heads: 16
10.0.16.14: all_head_size: 1024
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 1024])
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 4096])
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: num_attention_heads: 16
10.0.16.14: all_head_size: 1024
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 1024])
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 4096])
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: num_attention_heads: 16
10.0.16.14: all_head_size: 1024
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 1024])
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 4096])
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: num_attention_heads: 16
10.0.16.14: all_head_size: 1024
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 1024])
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 4096])
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: num_attention_heads: 16
10.0.16.14: all_head_size: 1024
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 1024])
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 4096])
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: num_attention_heads: 16
10.0.16.14: all_head_size: 1024
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 1024])
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 4096])
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: num_attention_heads: 16
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.14: all_head_size: 1024
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 1024])
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 4096])
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: num_attention_heads: 16
10.0.16.14: all_head_size: 1024
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 1024])
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 4096])
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: num_attention_heads: 16
10.0.16.14: all_head_size: 1024
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 1024])
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 4096])
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: num_attention_heads: 16
10.0.16.14: all_head_size: 1024
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 1024])
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 4096])
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: num_attention_heads: 16
10.0.16.14: all_head_size: 1024
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 1024])
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 4096])
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: num_attention_heads: 16
10.0.16.14: all_head_size: 1024
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 1024])
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 4096])
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: num_attention_heads: 16
10.0.16.14: all_head_size: 1024
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 1024])
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.14: name: output.dense in all_reduce_linears, weight shape: torch.Size([1024, 4096])
10.0.16.14: _replace_module: Embedding(512, 1024)
10.0.16.14: _replace_module: LayerNorm((1024,), eps=1e-07, elementwise_affine=True)
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.14: replace without policy
10.0.16.14: all_reduce_linears: ('output.dense',)
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.14: _replace_module: ContextPooler(
10.0.16.14:   (dense): Linear(in_features=1024, out_features=1024, bias=True)
10.0.16.14:   (dropout): StableDropout()
10.0.16.14: )
10.0.16.14: _replace_module: Linear(in_features=1024, out_features=1024, bias=True)
10.0.16.14: _replace_module: StableDropout()
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.14: _replace_module: Linear(in_features=1024, out_features=2, bias=True)
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.14: _replace_module: StableDropout()
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.13: replace without policy
10.0.16.13: all_reduce_linears: ('output.dense',)
10.0.16.14: [2024-05-15 09:15:37,411] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 77745
10.0.16.14: [2024-05-15 09:15:37,411] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 77746
10.0.16.14: [2024-05-15 09:15:37,607] [ERROR] [launch.py:321:sigkill_handler] ['/home/kechengsheji/anaconda3/envs/Test04/bin/python', '-u', 'test-deberta.py', '--local_rank=1', '--batch_size', '128'] exits with return code = 1
10.0.16.13: rank: 2 end2end time is 2693.829571759259 ms
10.0.16.13: rank: 2 model time is 2415.02619877568 ms
10.0.16.13: [2024-05-15 17:16:55,919] [INFO] [launch.py:347:main] Process 1186227 exits successfully.
10.0.16.13: [2024-05-15 17:16:57,921] [INFO] [launch.py:347:main] Process 1186228 exits successfully.
